---
layout: post
title: "Transforming Text Into Knowledge API"
url: 'http://kinlane.com/2010/08/22/transforming-text-into-knowledge-api/'
image: 'http://www.alchemyapi.com/images/alchemyAPI.jpg'
---

[<img class="alignnone c1" title="AlchemyAPI" src="http://www.alchemyapi.com/images/alchemyAPI.jpg" alt="" width="259" height="57" align="right" />][1]I had a chance to play with the [AlchemyAPI][1] I came across today. [AlchemyAPI][1] is a semantic tagging and text mining Application Programming Interface (API).

I have about 10K web pages I want to extract top keywords and key phrases from. I want meaning extracted from the words on each page.

[AlchemyAPI][1] provides nine methods:

  * **Named Entity Extraction** \- Identifies people, companies, organizations, cities, geographic features and other entities within content provided.
  * **Topic Categorization** \- Applies a categorization for the content provided.
  * **Language Detection** \- Provides language detection for the content provided.
  * **Concept Tagging** \- Tagging of the content provided.
  * **Keyword Extraction** \- Provides topic / keyword / tag extraction for the content provided.
  * **Text Extraction / Web Page Cleaning** \- Provides mechanism to extract the page text from web pages.
  * **Structured Content Scraping** \- Ability to mine structured data from web pages.
  * **Microformats Parsing / Extraction** \- Extraction of hCard, adr, geo, and rel formatted content from any web page.
  * **RSS / ATOM Feed Detection** \- Provides RSS / ATOM feed detection in any web pages.
I'm only using the keyword extraction and named entity extraction for what I am doing. The whole API provides some great tools to quickly harvest, scrape and process content from the open Internet.

Their API is extremely easy to use and you can be up and running in about 10 minutes harvesting and processing pages.

   [1]: http://www.alchemyapi.com/
